#! /bin/sh -e

# All lines beginning with `# DP:' are a description of the patch.
# DP: Description: parisc patches based on 50_glibc232-hppa-full-nptl-2003-10-22.
#		   This dpatch excepts (1) patches applied already in cvs
#		   (2) hppa ldcw spinlock fix.  (2) should be merged in future.
# DP: Related bugs: 
# DP: Dpatch author: GOTO Masanori <gotom@debian.org> 
# DP: Patch author: Carlos O'Donell <carlos@baldric.uwo.ca>
# DP: Upstream status: Pending
# DP: Status Details: 
# DP: Date: 2005-03-14

PATCHLEVEL=1

if [ $# -ne 2 ]; then
    echo >&2 "`basename $0`: script expects -patch|-unpatch as argument"
    exit 1
fi
case "$1" in
    -patch) patch -d "$2" -f --no-backup-if-mismatch -p$PATCHLEVEL < $0;;
    -unpatch) patch -d "$2" -f --no-backup-if-mismatch -R -p$PATCHLEVEL < $0;;
    *)
	echo >&2 "`basename $0`: script expects -patch|-unpatch as argument"
	exit 1
esac
exit 0

# append the patch here and adjust the -p? flag in the patch calls.
# Patched with:
#
# Linuxthread fixes:
# patches-2003-10-14/glibc23-00.a-noarch-pthreads
# patches-2003-10-14/glibc23-00.a1-noarch-sgu
# patches-2003-10-14/glibc23-00.b-noarch-sysdeps-pthreads
# patches-2003-10-14/glibc23-00.c2-hppa-pthreads
# patches-2003-10-14/glibc23-01d-hppa-dl-machine
# 
# libgcc compat fixes:
# patches-2003-10-14/glibc23-02-hppa-compat
#
# Introduce atomicity warnings:
# patches-2003-10-14/glibc23-03-hppa-atomicity
#
# Don't align all mallocs at 16:
# patches-2003-10-14/glibc23-04-hppa-malloc8
#
# Sysdep updates including cancellation:
# patches-2003-10-14/glibc23-05n-hppa-sysdep
# patches-2003-10-14/glibc23-06r-hppa-sysdep-cancel
# patches-2003-10-14/glibc23-07b-hppa-sysdep2
#	= Patched 2003-10-20 to remove load offset typo
# Elf entry fix for ld, removes kernel hack:
# patches-2003-10-14/glibc23-09-hppa-entry
#
# Patch to use new atomic structure:
# patches-2003-10-14/glibc23-12-hppa-oldsemaphore
#
# We have sjlj exceptions but compat code was for dwarf:
# patches-2003-10-14/glibc23-13-hppa-framestatefor
#
# Fix function pointer resolving (needs to move to new generic method):
# patches-2003-10-14/glibc23-14-hppa-dlfptr
#
# Fixes getaddrinfo from upstream:
# patches-2003-10-14/glibc23-15-generic-getaddrinfo
#
# Include new pthreadtypes for hppa:
# patches-2003-10-14/glibc23-17b-hppa-pthreadtypes
#
# Fix warnings:
# patches-2003-10-14/glibc23-18-generic-sysctlh
#
# Add semtimedop for hppa:
# patches-2003-10-14/glibc23-19-hppa-semtimedop
#
# Fix symbol resolution issues:
# patches-2003-10-14/glibc23-20c-hppa-ptmachine
#
# Make the kernelstat 64-bit uncompatible:
# patches-2003-10-14/glibc23-21-hppa-kernelstat
#
# Fixup C version of syscalls:
# patches-2003-10-14/glibc23-22c-hppa-sysdepc
#
# Fixes for sjlj versus dwarf compat code:
# patches-2003-10-14/glibc23-23-hppa-unwind-dw2
#
# Allow hppa to get at the linkmap:
# patches-2003-10-14/glibc23-25b-dynamic-link
#
# Fix all of the assembly for hppa fpu code:
# patches-2003-10-14/glibc23-26e-fpu
#	= Patched 2003-10-20 to fix FE_INEXACT failures
#
# Add small amount of debugging code to make locale 
# generation easier to understand:
# patches-2003-10-14/glibc23-27-debug-gen-locale
#
# Fixup clone to save/restore pic register:
# patches-2003-10-14/glibc23-28c-hppa-clone
#
# Fixup prototype warnings:
# patches-2003-10-14/glibc23-29-hppa-prototypes
#
# Fixup bad cats:
# patches-2003-10-14/glibc23-30-hppa-casts
#
# Fixup warning:
# patches-2003-10-14/glibc23-31-generic-unix-Makefile
#
# Implement proper non-linuxthread locking:
# patches-2003-10-14/glibc23-32-hppa-thread-m
# patches-2003-10-14/glibc23-32a-hppa-thread-m
#
# Fixup warnings:
# patches-2003-10-14/glibc23-33-generic-internals
#
# These patches generate rejects, and those rejects were then dealt
# with on a per patch basis. Some were discarded others merged.
#
# append the patch here and adjust the -p? flag in the patch calls.


#
# it seems we do not need it...
#
#diff -urN glibc-2.3.2-orig-debian/elf/dynamic-link.h glibc-2.3.2/elf/dynamic-link.h
#--- glibc-2.3.2-orig-debian/elf/dynamic-link.h	2003-10-22 01:06:09.000000000 -0400
#+++ glibc-2.3.2/elf/dynamic-link.h	2003-10-22 01:11:53.000000000 -0400
#@@ -39,12 +39,21 @@
# elf_machine_rela (struct link_map *map, const ElfW(Rela) *reloc,
# 		  const ElfW(Sym) *sym, const struct r_found_version *version,
# 		  void *const reloc_addr);
#+# if ELF_MACHINE_REL_RELATIVE_NEEDSLINKMAP
#+auto void __attribute__((always_inline))
#+elf_machine_rel_relative (struct link_map *map, ElfW(Addr) l_addr, const ElfW(Rel) *reloc,
#+			  void *const reloc_addr);
#+auto void __attribute__((always_inline))
#+elf_machine_rela_relative (struct link_map *map, ElfW(Addr) l_addr, const ElfW(Rela) *reloc,
#+			  void *const reloc_addr);
#+# else
# auto void __attribute__((always_inline))
# elf_machine_rel_relative (ElfW(Addr) l_addr, const ElfW(Rel) *reloc,
# 			  void *const reloc_addr);
# auto void __attribute__((always_inline))
# elf_machine_rela_relative (ElfW(Addr) l_addr, const ElfW(Rela) *reloc,
# 			   void *const reloc_addr);
#+# endif
# # if ELF_MACHINE_NO_RELA || defined ELF_MACHINE_PLT_REL
# auto void __attribute__((always_inline))
# elf_machine_lazy_rel (struct link_map *map,


#
# no, it's not applied yet.  it may be needed...  we need investigation.
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/attr.c glibc-2.3.2/linuxthreads/attr.c
#--- glibc-2.3.2-orig-debian/linuxthreads/attr.c	2003-10-22 01:06:10.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/attr.c	2003-10-22 01:07:38.000000000 -0400
#@@ -450,12 +450,19 @@
# 		{
# 		  /* Found the entry.  Now we have the info we need.  */
# 		  attr->__stacksize = rl.rlim_cur;
#+#ifdef _STACK_GROWS_DOWN
# 		  attr->__stackaddr = (void *) to;
#-
#+#else
#+                  attr->__stackaddr = (void *) from;
#+#endif
# 		  /* The limit might be too high.  This is a bogus
# 		     situation but try to avoid making it worse.  */
# 		  if ((size_t) attr->__stacksize > (size_t) attr->__stackaddr)
#+#ifdef _STACK_GROWS_DOWN
# 		    attr->__stacksize = (size_t) attr->__stackaddr;
#+#else
#+                    attr->__stacksize = (size_t)(to - from);
#+#endif
# 
# 		  /* We succeed and no need to look further.  */
# 		  ret = 0;


#
# no, not applied yet. (lock change)
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/descr.h glibc-2.3.2/linuxthreads/descr.h
#--- glibc-2.3.2-orig-debian/linuxthreads/descr.h	2003-10-22 01:06:10.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/descr.h	2003-10-22 01:07:38.000000000 -0400
#@@ -71,7 +71,7 @@
# /* Atomic counter made possible by compare_and_swap */
# struct pthread_atomic {
#   long p_count;
#-  int p_spinlock;
#+  __atomic_lock_t p_spinlock;
# };
 


#
# not applied yet. (lock change)
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/oldsemaphore.c glibc-2.3.2/linuxthreads/oldsemaphore.c
#--- glibc-2.3.2-orig-debian/linuxthreads/oldsemaphore.c	2003-10-22 01:03:57.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/oldsemaphore.c	2003-10-22 01:07:38.000000000 -0400
#@@ -31,7 +31,7 @@
# 
# typedef struct {
#     long int sem_status;
#-    int sem_spinlock;
#+    __atomic_lock_t sem_spinlock;
# } old_sem_t;
# 
# extern int __old_sem_init (old_sem_t *__sem, int __pshared, unsigned int __value);


#
# not applied yet.  (I don't know why it's needed, but lock change?)
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/pt-machine.c glibc-2.3.2/linuxthreads/pt-machine.c
#--- glibc-2.3.2-orig-debian/linuxthreads/pt-machine.c	2003-10-22 01:03:57.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/pt-machine.c	2003-10-22 01:07:38.000000000 -0400
#@@ -19,7 +19,9 @@
# 
# #define PT_EI
# 
#-extern long int testandset (int *spinlock);
#+#include <pthread.h>
#+
#+extern long int testandset (__atomic_lock_t *spinlock);
# extern int __compare_and_swap (long int *p, long int oldval, long int newval);
# 
# #include <pt-machine.h>


#
# partially applied: 893, 908.  but not for SPINLOCK (lock change).
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/pthread.c glibc-2.3.2/linuxthreads/pthread.c
#--- glibc-2.3.2-orig-debian/linuxthreads/pthread.c	2003-10-22 01:06:16.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/pthread.c	2003-10-22 01:07:38.000000000 -0400
#@@ -300,9 +300,9 @@
#   pthread_descr self;
# 
#   /* First of all init __pthread_handles[0] and [1] if needed.  */
#-# if __LT_SPINLOCK_INIT != 0
#-  __pthread_handles[0].h_lock = __LOCK_INITIALIZER;
#-  __pthread_handles[1].h_lock = __LOCK_INITIALIZER;
#+# ifdef __LT_INITIALIZER_NOT_ZERO
#+  __pthread_handles[0].h_lock = __LOCK_ALT_INITIALIZER;
#+  __pthread_handles[1].h_lock = __LOCK_ALT_INITIALIZER;
# # endif
# # ifndef SHARED
#   /* Unlike in the dynamically linked case the dynamic linker has not
#@@ -370,7 +370,7 @@
# # endif
#   /* self->p_start_args need not be initialized, it's all zero.  */
#   self->p_userstack = 1;
#-# if __LT_SPINLOCK_INIT != 0
#+# ifdef __LT_INITIALIZER_NOT_ZERO 
#   self->p_resume_count = (struct pthread_atomic) __ATOMIC_INITIALIZER;
# # endif
#   self->p_alloca_cutoff = __MAX_ALLOCA_CUTOFF;
#@@ -384,9 +384,9 @@
# #else  /* USE_TLS */
# 
#   /* First of all init __pthread_handles[0] and [1].  */
#-# if __LT_SPINLOCK_INIT != 0
#-  __pthread_handles[0].h_lock = __LOCK_INITIALIZER;
#-  __pthread_handles[1].h_lock = __LOCK_INITIALIZER;
#+# ifdef __LT_INITIALIZER_NOT_ZERO
#+  __pthread_handles[0].h_lock = __LOCK_ALT_INITIALIZER;
#+  __pthread_handles[1].h_lock = __LOCK_ALT_INITIALIZER;
# # endif
#   __pthread_handles[0].h_descr = &__pthread_initial_thread;
#   __pthread_handles[1].h_descr = &__pthread_manager_thread;
#@@ -893,7 +893,11 @@
#   /* __pthread_handles[0] is the initial thread, __pthread_handles[1] is
#      the manager threads handled specially in thread_self(), so start at 2 */
#   h = __pthread_handles + 2;
#+# ifdef _STACK_GROWS_UP
#+  while (! (sp >= (char *) h->h_descr && sp < h->h_descr->p_guardaddr)) h++;
#+# else
#   while (! (sp <= (char *) h->h_descr && sp >= h->h_bottom)) h++;
#+# endif
#   return h->h_descr;
# }
# 
#@@ -908,11 +912,22 @@
#     return manager_thread;
#   h = __pthread_handles + 2;
# # ifdef USE_TLS
#+#  ifdef _STACK_GROWS_UP
#+  while (h->h_descr == NULL
#+	 || ! (sp >= h->h_descr->p_stackaddr && 
#+	       sp < h->h_descr->p_guardaddr))
#+#  else
#   while (h->h_descr == NULL
#-	 || ! (sp <= (char *) h->h_descr->p_stackaddr && sp >= h->h_bottom))
#+	 || ! (sp <= h->h_descr->p_stackaddr && 
#+	       sp >= h->h_bottom))
#+#  endif
#     h++;
# # else
#+#  ifdef _STACK_GROWS_UP
#+  while (! (sp >= (char *) h->h_descr && sp < h->h_descr->p_guardaddr))
#+#  else
#   while (! (sp <= (char *) h->h_descr && sp >= h->h_bottom))
#+#  endif
#     h++;
# # endif
#   return h->h_descr;


#
# not (lock change)
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/spinlock.c glibc-2.3.2/linuxthreads/spinlock.c
#--- glibc-2.3.2-orig-debian/linuxthreads/spinlock.c	2003-10-22 01:03:57.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/spinlock.c	2003-10-22 01:07:38.000000000 -0400
#@@ -24,9 +24,9 @@
# #include "spinlock.h"
# #include "restart.h"
# 
#-static void __pthread_acquire(int * spinlock);
#+static void __pthread_acquire(__atomic_lock_t * spinlock);
# 
#-static inline void __pthread_release(int * spinlock)
#+static inline void __pthread_release(__atomic_lock_t * spinlock)
# {
#   WRITE_MEMORY_BARRIER();
#   *spinlock = __LT_SPINLOCK_INIT;
#@@ -269,11 +269,11 @@
# struct wait_node {
#   struct wait_node *next;	/* Next node in null terminated linked list */
#   pthread_descr thr;		/* The thread waiting with this node */
#-  int abandoned;		/* Atomic flag */
#+  __atomic_lock_t abandoned;	/* Atomic flag */
# };
# 
# static long wait_node_free_list;
#-static int wait_node_free_list_spinlock;
#+__pthread_lock_define_initialized(static, wait_node_free_list_spinlock);
# 
# /* Allocate a new node from the head of the free list using an atomic
#    operation, or else using malloc if that list is empty.  A fundamental
#@@ -376,7 +376,7 @@
#       if (self == NULL)
# 	self = thread_self();
# 
#-      wait_node.abandoned = 0;
#+      wait_node.abandoned = __LT_SPINLOCK_INIT;
#       wait_node.next = (struct wait_node *) lock->__status;
#       wait_node.thr = self;
#       lock->__status = (long) &wait_node;
#@@ -402,7 +402,7 @@
#       wait_node.thr = self;
#       newstatus = (long) &wait_node;
#     }
#-    wait_node.abandoned = 0;
#+    wait_node.abandoned = __LT_SPINLOCK_INIT;
#     wait_node.next = (struct wait_node *) oldstatus;
#     /* Make sure the store in wait_node.next completes before performing
#        the compare-and-swap */
#@@ -451,7 +451,7 @@
#       if (self == NULL)
# 	self = thread_self();
# 
#-      p_wait_node->abandoned = 0;
#+      p_wait_node->abandoned = __LT_SPINLOCK_INIT;
#       p_wait_node->next = (struct wait_node *) lock->__status;
#       p_wait_node->thr = self;
#       lock->__status = (long) p_wait_node;
#@@ -474,7 +474,7 @@
#       p_wait_node->thr = self;
#       newstatus = (long) p_wait_node;
#     }
#-    p_wait_node->abandoned = 0;
#+    p_wait_node->abandoned = __LT_SPINLOCK_INIT;
#     p_wait_node->next = (struct wait_node *) oldstatus;
#     /* Make sure the store in wait_node.next completes before performing
#        the compare-and-swap */
#@@ -574,7 +574,7 @@
#     while (p_node != (struct wait_node *) 1) {
#       int prio;
# 
#-      if (p_node->abandoned) {
#+      if (lock_held(&p_node->abandoned)) {
# 	/* Remove abandoned node. */
# #if defined TEST_FOR_COMPARE_AND_SWAP
# 	if (!__pthread_has_cas)
#@@ -662,7 +662,7 @@
# #if !defined HAS_COMPARE_AND_SWAP || defined TEST_FOR_COMPARE_AND_SWAP
# 
# int __pthread_compare_and_swap(long * ptr, long oldval, long newval,
#-                               int * spinlock)
#+                               __atomic_lock_t * spinlock)
# {
#   int res;
# 
#@@ -699,7 +699,7 @@
#    - When nanosleep() returns, we try again, doing MAX_SPIN_COUNT
#      sched_yield(), then sleeping again if needed. */
# 
#-static void __pthread_acquire(int * spinlock)
#+static void __pthread_acquire(__atomic_lock_t * spinlock)	
# {
#   int cnt = 0;
#   struct timespec tm;


#
# not (lock change)
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/spinlock.h glibc-2.3.2/linuxthreads/spinlock.h
#--- glibc-2.3.2-orig-debian/linuxthreads/spinlock.h	2003-10-22 01:06:10.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/spinlock.h	2003-10-22 01:07:38.000000000 -0400
#@@ -33,14 +33,28 @@
# #endif
# #endif
# 
#+/* Define lock_held for all arches that don't need a modified copy. */
#+#ifndef __LT_INITIALIZER_NOT_ZERO
#+# define lock_held(p) *(p)
#+#endif
#+
#+/* Initliazers for possibly complex structures */
#+#ifdef __LT_INITIALIZER_NOT_ZERO
#+# define __pthread_lock_define_initialized(CLASS,NAME) \
#+	CLASS __atomic_lock_t NAME = __LT_SPINLOCK_ALT_INIT
#+#else
#+# define __pthread_lock_define_initialized(CLASS,NAME) \
#+	CLASS __atomic_lock_t NAME
#+#endif
#+
# #if defined(TEST_FOR_COMPARE_AND_SWAP)
# 
# extern int __pthread_has_cas;
# extern int __pthread_compare_and_swap(long * ptr, long oldval, long newval,
#-                                      int * spinlock);
#+                                      __atomic_lock_t * spinlock);
# 
# static inline int compare_and_swap(long * ptr, long oldval, long newval,
#-                                   int * spinlock)
#+                                   __atomic_lock_t * spinlock)
# {
#   if (__builtin_expect (__pthread_has_cas, 1))
#     return __compare_and_swap(ptr, oldval, newval);
#@@ -58,7 +72,7 @@
# 
# static inline int
# compare_and_swap_with_release_semantics (long * ptr, long oldval,
#-					 long newval, int * spinlock)
#+					 long newval, __atomic_lock_t * spinlock)
# {
#   return __compare_and_swap_with_release_semantics (ptr, oldval,
# 						    newval);
#@@ -67,7 +81,7 @@
# #endif
# 
# static inline int compare_and_swap(long * ptr, long oldval, long newval,
#-                                   int * spinlock)
#+                                   __atomic_lock_t * spinlock)
# {
#   return __compare_and_swap(ptr, oldval, newval);
# }
#@@ -75,10 +89,10 @@
# #else
# 
# extern int __pthread_compare_and_swap(long * ptr, long oldval, long newval,
#-                                      int * spinlock);
#+                                      __atomic_lock_t * spinlock);
# 
# static inline int compare_and_swap(long * ptr, long oldval, long newval,
#-                                   int * spinlock)
#+                                   __atomic_lock_t * spinlock)
# {
#   return __pthread_compare_and_swap(ptr, oldval, newval, spinlock);
# }


#
# not applied (lock change)
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/sysdeps/hppa/pspinlock.c glibc-2.3.2/linuxthreads/sysdeps/hppa/pspinlock.c
#--- glibc-2.3.2-orig-debian/linuxthreads/sysdeps/hppa/pspinlock.c	2003-10-22 01:03:57.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/sysdeps/hppa/pspinlock.c	2003-10-22 01:07:38.000000000 -0400
#@@ -24,13 +24,10 @@
# int
# __pthread_spin_lock (pthread_spinlock_t *lock)
# {
#-  unsigned int val;
#+  volatile unsigned int *addr = __ldcw_align (lock);
# 
#-  do
#-    asm volatile ("ldcw %1,%0"
#-		  : "=r" (val), "=m" (*lock)
#-		  : "m" (*lock));
#-  while (!val);
#+  while (__ldcw (addr) == 0)
#+    while (*addr == 0) ;
# 
#   return 0;
# }
#@@ -40,13 +37,9 @@
# int
# __pthread_spin_trylock (pthread_spinlock_t *lock)
# {
#-  unsigned int val;
#+  volatile unsigned int *a = __ldcw_align (lock);
# 
#-  asm volatile ("ldcw %1,%0"
#-		: "=r" (val), "=m" (*lock)
#-		: "m" (*lock));
#-
#-  return val ? 0 : EBUSY;
#+  return __ldcw (a) ? 0 : EBUSY;
# }
# weak_alias (__pthread_spin_trylock, pthread_spin_trylock)
# 
#@@ -54,7 +47,9 @@
# int
# __pthread_spin_unlock (pthread_spinlock_t *lock)
# {
#-  *lock = 1;
#+  volatile unsigned int *a = __ldcw_align (lock);
#+
#+  *a = 1;
#   return 0;
# }
# weak_alias (__pthread_spin_unlock, pthread_spin_unlock)
#@@ -66,7 +61,9 @@
#   /* We can ignore the `pshared' parameter.  Since we are busy-waiting
#      all processes which can access the memory location `lock' points
#      to can use the spinlock.  */
#-  *lock = 1;
#+  volatile unsigned int *a = __ldcw_align (lock);
#+
#+  *a = 1;
#   return 0;
# }
# weak_alias (__pthread_spin_init, pthread_spin_init)


#
# not applied (lock change)
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/sysdeps/hppa/pt-machine.h glibc-2.3.2/linuxthreads/sysdeps/hppa/pt-machine.h
#--- glibc-2.3.2-orig-debian/linuxthreads/sysdeps/hppa/pt-machine.h	2003-10-22 01:06:10.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/sysdeps/hppa/pt-machine.h	2003-10-22 01:12:51.000000000 -0400
#@@ -22,41 +22,97 @@
# #ifndef _PT_MACHINE_H
# #define _PT_MACHINE_H   1
# 
#+#include <sys/types.h>
# #include <bits/initspin.h>
# 
# #ifndef PT_EI
# # define PT_EI extern inline __attribute__ ((always_inline))
# #endif
# 
#-extern long int testandset (int *spinlock);
#-extern int __compare_and_swap (long int *p, long int oldval, long int newval);
#+extern inline long int testandset (__atomic_lock_t *spinlock);
#+extern inline int __compare_and_swap (long int *p, long int oldval, long int newval);
#+extern inline int lock_held (__atomic_lock_t *spinlock); 
#+extern inline int __load_and_clear (__atomic_lock_t *spinlock);
# 
# /* Get some notion of the current stack.  Need not be exactly the top
#    of the stack, just something somewhere in the current frame.  */
# #define CURRENT_STACK_FRAME  stack_pointer
# register char * stack_pointer __asm__ ("%r30");
# 
#+/* Get/Set thread-specific pointer.  We have to call into the kernel to
#+ * modify it, but we can read it in user mode.  */
#+
#+#define THREAD_SELF __get_cr27()
#+
#+static inline struct _pthread_descr_struct * __get_cr27(void)
#+{
#+	long cr27;
#+	asm("mfctl %%cr27, %0" : "=r" (cr27) : );
#+	return (struct _pthread_descr_struct *) cr27;
#+}
#+
#+#define INIT_THREAD_SELF(descr, nr) __set_cr27(descr)
#+
#+static inline void __set_cr27(struct _pthread_descr_struct * cr27)
#+{
#+	asm(
#+		"ble	0xe0(%%sr2, %%r0)\n\t"
#+		"copy	%0, %%r26"
#+	 : : "r" (cr27) : "r26" );
#+}
#+
#+/* We want the OS to assign stack addresses.  */
#+#define FLOATING_STACKS	1
#+#define ARCH_STACK_MAX_SIZE	8*1024*1024
# 
# /* The hppa only has one atomic read and modify memory operation,
#    load and clear, so hppa spinlocks must use zero to signify that
#-   someone is holding the lock.  */
#+   someone is holding the lock.  The address used for the ldcw
#+   semaphore must be 16-byte aligned.  */
#+#define __ldcw(a) ({ \
#+  unsigned int __ret;							\
#+  __asm__ __volatile__("ldcw 0(%2),%0"					\
#+                      : "=r" (__ret), "=m" (*(a)) : "r" (a));		\
#+  __ret;								\
#+})
#+
#+/* Because malloc only guarantees 8-byte alignment for malloc'd data,
#+   and GCC only guarantees 8-byte alignment for stack locals, we can't
#+   be assured of 16-byte alignment for atomic lock data even if we
#+   specify "__attribute ((aligned(16)))" in the type declaration.  So,
#+   we use a struct containing an array of four ints for the atomic lock
#+   type and dynamically select the 16-byte aligned int from the array
#+   for the semaphore.  */
#+#define __PA_LDCW_ALIGNMENT 16
#+#define __ldcw_align(a) ({ \
#+  volatile unsigned int __ret = (unsigned int) a;			\
#+  if ((__ret & ~(__PA_LDCW_ALIGNMENT - 1)) < (unsigned int) a)		\
#+    __ret = (__ret & ~(__PA_LDCW_ALIGNMENT - 1)) + __PA_LDCW_ALIGNMENT; \
#+  (unsigned int *) __ret;						\
#+})
# 
#-#define xstr(s) str(s)
#-#define str(s) #s
# /* Spinlock implementation; required.  */
#-PT_EI long int
#-testandset (int *spinlock)
#+PT_EI int
#+__load_and_clear (__atomic_lock_t *spinlock)
# {
#-  int ret;
#+  volatile unsigned int *a = __ldcw_align (spinlock);
# 
#-  __asm__ __volatile__(
#-       "ldcw 0(%2),%0"
#-       : "=r"(ret), "=m"(*spinlock)
#-       : "r"(spinlock));
#+  return __ldcw (a);
#+}
# 
#-  return ret == 0;
#+/* Emulate testandset */
#+PT_EI long int
#+testandset (__atomic_lock_t *spinlock)
#+{
#+  return (__load_and_clear(spinlock) == 0);
# }
#-#undef str
#-#undef xstr
# 
#+PT_EI int
#+lock_held (__atomic_lock_t *spinlock)
#+{
#+  volatile unsigned int *a = __ldcw_align (spinlock);
#+
#+  return *a == 0;
#+}
#+		
# #endif /* pt-machine.h */



#
# not (lock change).
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/sysdeps/pthread/bits/libc-lock.h glibc-2.3.2/linuxthreads/sysdeps/pthread/bits/libc-lock.h
#--- glibc-2.3.2-orig-debian/linuxthreads/sysdeps/pthread/bits/libc-lock.h	2003-10-22 01:06:16.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/sysdeps/pthread/bits/libc-lock.h	2003-10-22 01:07:38.000000000 -0400
#@@ -71,12 +71,12 @@
#    initialized locks must be set to one due to the lack of normal
#    atomic operations.) */
# 
#-#if __LT_SPINLOCK_INIT == 0
#+#ifdef __LT_INITIALIZER_NOT_ZERO
# #  define __libc_lock_define_initialized(CLASS,NAME) \
#-  CLASS __libc_lock_t NAME;
#+  CLASS __libc_lock_t NAME = PTHREAD_MUTEX_INITIALIZER;
# #else
# #  define __libc_lock_define_initialized(CLASS,NAME) \
#-  CLASS __libc_lock_t NAME = PTHREAD_MUTEX_INITIALIZER;
#+  CLASS __libc_lock_t NAME;
# #endif
# 
# #define __libc_rwlock_define_initialized(CLASS,NAME) \


#
# not. (lock change)
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/sysdeps/pthread/bits/pthreadtypes.h glibc-2.3.2/linuxthreads/sysdeps/pthread/bits/pthreadtypes.h
#--- glibc-2.3.2-orig-debian/linuxthreads/sysdeps/pthread/bits/pthreadtypes.h	2003-10-22 01:03:57.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/sysdeps/pthread/bits/pthreadtypes.h	2003-10-22 01:07:38.000000000 -0400
#@@ -22,12 +22,14 @@
# #define __need_schedparam
# #include <bits/sched.h>
# 
#+typedef int __atomic_lock_t;
#+
# /* Fast locks (not abstract because mutexes and conditions aren't abstract). */
# struct _pthread_fastlock
# {
#-  long int __status;   /* "Free" or "taken" or head of waiting list */
#-  int __spinlock;      /* Used by compare_and_swap emulation. Also,
#-			  adaptive SMP lock stores spin count here. */
#+  long int __status;		/* "Free" or "taken" or head of waiting list */
#+  __atomic_lock_t __spinlock;	/* Used by compare_and_swap emulation. Also,
#+				   adaptive SMP lock stores spin count here. */
# };
# 
# #ifndef _PTHREAD_DESCR_DEFINED



#
# not (lock change)
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/sysdeps/unix/sysv/linux/hppa/bits/initspin.h glibc-2.3.2/linuxthreads/sysdeps/unix/sysv/linux/hppa/bits/initspin.h
#--- glibc-2.3.2-orig-debian/linuxthreads/sysdeps/unix/sysv/linux/hppa/bits/initspin.h	2003-10-22 01:03:57.000000000 -0400
#+++ glibc-2.3.2/linuxthreads/sysdeps/unix/sysv/linux/hppa/bits/initspin.h	2003-10-22 01:07:38.000000000 -0400
#@@ -19,9 +19,23 @@
# 
# /* Initial value of a spinlock.  PA-RISC only implements atomic load
#    and clear so this must be non-zero. */
#-#define __LT_SPINLOCK_INIT 1
#+#define __LT_SPINLOCK_INIT ((__atomic_lock_t) { { 1, 1, 1, 1 } })
#+
#+/* Initialize global spinlocks without cast, generally macro wrapped */
#+#define __LT_SPINLOCK_ALT_INIT { { 1, 1, 1, 1 } }
#+
#+/* Macros for lock initializers, not using the above definition.
#+   The above definition is not used in the case that static initializers
#+   use this value. */
#+#define __LOCK_INITIALIZER { __LT_SPINLOCK_ALT_INIT, 0 }
#+
#+/* Used to initialize _pthread_fastlock's in non-static case */
#+#define __LOCK_ALT_INITIALIZER ((struct _pthread_fastlock){ __LT_SPINLOCK_INIT, 0 })
#+
#+/* Used in pthread_atomic initialization */
#+#define __ATOMIC_INITIALIZER { 0, __LT_SPINLOCK_ALT_INIT }
#+
#+/* Tell the rest of the code that the initializer is non-zero without
#+   explaining it's internal structure */
#+#define __LT_INITIALIZER_NOT_ZERO
# 
#-/* Macros for lock initializers, using the above definition. */
#-#define __LOCK_INITIALIZER { 0, __LT_SPINLOCK_INIT }
#-#define __ALT_LOCK_INITIALIZER { 0, __LT_SPINLOCK_INIT }
#-#define __ATOMIC_INITIALIZER { 0, __LT_SPINLOCK_INIT }



#
# not (lock change)
#
#diff -urN glibc-2.3.2-orig-debian/linuxthreads/sysdeps/unix/sysv/linux/hppa/bits/pthreadtypes.h glibc-2.3.2/linuxthreads/sysdeps/unix/sysv/linux/hppa/bits/pthreadtypes.h
#--- glibc-2.3.2-orig-debian/linuxthreads/sysdeps/unix/sysv/linux/hppa/bits/pthreadtypes.h	1969-12-31 19:00:00.000000000 -0500
#+++ glibc-2.3.2/linuxthreads/sysdeps/unix/sysv/linux/hppa/bits/pthreadtypes.h	2003-10-22 01:07:38.000000000 -0400
#@@ -0,0 +1,160 @@
#+/* Linuxthreads - a simple clone()-based implementation of Posix        */
#+/* threads for Linux.                                                   */
#+/* Copyright (C) 1996 Xavier Leroy (Xavier.Leroy@inria.fr)              */
#+/*                                                                      */
#+/* This program is free software; you can redistribute it and/or        */
#+/* modify it under the terms of the GNU Library General Public License  */
#+/* as published by the Free Software Foundation; either version 2       */
#+/* of the License, or (at your option) any later version.               */
#+/*                                                                      */
#+/* This program is distributed in the hope that it will be useful,      */
#+/* but WITHOUT ANY WARRANTY; without even the implied warranty of       */
#+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the        */
#+/* GNU Library General Public License for more details.                 */
#+
#+#if !defined _BITS_TYPES_H && !defined _PTHREAD_H
#+# error "Never include <bits/pthreadtypes.h> directly; use <sys/types.h> instead."
#+#endif
#+
#+#ifndef _BITS_PTHREADTYPES_H
#+#define _BITS_PTHREADTYPES_H	1
#+
#+#define __need_schedparam
#+#include <bits/sched.h>
#+
#+/* We need 128-bit alignment for the ldcw semaphore.  At most, we are
#+   assured of 64-bit alignment for stack locals and malloc'd data.  Thus,
#+   we use a struct with four ints for the atomic lock type.  The locking
#+   code will figure out which of the four to use for the ldcw semaphore.  */
#+typedef volatile struct {
#+  int lock[4];
#+} __attribute__ ((aligned(16))) __atomic_lock_t;
#+
#+/* Fast locks (not abstract because mutexes and conditions aren't abstract). */
#+struct _pthread_fastlock
#+{
#+  __atomic_lock_t __spinlock;	/* Used by compare_and_swap emulation.  Also,
#+				   adaptive SMP lock stores spin count here. */
#+  long int __status;		/* "Free" or "taken" or head of waiting list */
#+};
#+
#+#ifndef _PTHREAD_DESCR_DEFINED
#+/* Thread descriptors */
#+typedef struct _pthread_descr_struct *_pthread_descr;
#+# define _PTHREAD_DESCR_DEFINED
#+#endif
#+
#+
#+/* Attributes for threads.  */
#+typedef struct __pthread_attr_s
#+{
#+  int __detachstate;
#+  int __schedpolicy;
#+  struct __sched_param __schedparam;
#+  int __inheritsched;
#+  int __scope;
#+  size_t __guardsize;
#+  int __stackaddr_set;
#+  void *__stackaddr;
#+  size_t __stacksize;
#+} pthread_attr_t;
#+
#+
#+/* Conditions (not abstract because of PTHREAD_COND_INITIALIZER */
#+
#+#ifdef __GLIBC_HAVE_LONG_LONG
#+__extension__ typedef long long __pthread_cond_align_t;
#+#else
#+typedef long __pthread_cond_align_t;
#+#endif
#+
#+typedef struct
#+{
#+  struct _pthread_fastlock __c_lock; /* Protect against concurrent access */
#+  _pthread_descr __c_waiting;        /* Threads waiting on this condition */
#+  char __padding[48 - sizeof (struct _pthread_fastlock)
#+		 - sizeof (_pthread_descr) - sizeof (__pthread_cond_align_t)];
#+  __pthread_cond_align_t __align;
#+} pthread_cond_t;
#+
#+
#+/* Attribute for conditionally variables.  */
#+typedef struct
#+{
#+  int __dummy;
#+} pthread_condattr_t;
#+
#+/* Keys for thread-specific data */
#+typedef unsigned int pthread_key_t;
#+
#+
#+/* Mutexes (not abstract because of PTHREAD_MUTEX_INITIALIZER).  */
#+/* (The layout is unnatural to maintain binary compatibility
#+    with earlier releases of LinuxThreads.) */
#+typedef struct
#+{
#+  int __m_reserved;               /* Reserved for future use */
#+  int __m_count;                  /* Depth of recursive locking */
#+  _pthread_descr __m_owner;       /* Owner thread (if recursive or errcheck) */
#+  int __m_kind;                   /* Mutex kind: fast, recursive or errcheck */
#+  struct _pthread_fastlock __m_lock; /* Underlying fast lock */
#+} pthread_mutex_t;
#+
#+
#+/* Attribute for mutex.  */
#+typedef struct
#+{
#+  int __mutexkind;
#+} pthread_mutexattr_t;
#+
#+
#+/* Once-only execution */
#+typedef int pthread_once_t;
#+
#+
#+#ifdef __USE_UNIX98
#+/* Read-write locks.  */
#+typedef struct _pthread_rwlock_t
#+{
#+  struct _pthread_fastlock __rw_lock; /* Lock to guarantee mutual exclusion */
#+  int __rw_readers;                   /* Number of readers */
#+  _pthread_descr __rw_writer;         /* Identity of writer, or NULL if none */
#+  _pthread_descr __rw_read_waiting;   /* Threads waiting for reading */
#+  _pthread_descr __rw_write_waiting;  /* Threads waiting for writing */
#+  int __rw_kind;                      /* Reader/Writer preference selection */
#+  int __rw_pshared;                   /* Shared between processes or not */
#+} pthread_rwlock_t;
#+
#+
#+/* Attribute for read-write locks.  */
#+typedef struct
#+{
#+  int __lockkind;
#+  int __pshared;
#+} pthread_rwlockattr_t;
#+#endif
#+
#+#ifdef __USE_XOPEN2K
#+/* POSIX spinlock data type.  */
#+typedef __atomic_lock_t pthread_spinlock_t;
#+
#+/* POSIX barrier. */
#+typedef struct {
#+  struct _pthread_fastlock __ba_lock; /* Lock to guarantee mutual exclusion */
#+  int __ba_required;                  /* Threads needed for completion */
#+  int __ba_present;                   /* Threads waiting */
#+  _pthread_descr __ba_waiting;        /* Queue of waiting threads */
#+} pthread_barrier_t;
#+
#+/* barrier attribute */
#+typedef struct {
#+  int __pshared;
#+} pthread_barrierattr_t;
#+
#+#endif
#+
#+
#+/* Thread identifiers */
#+typedef unsigned long int pthread_t;
#+
#+#endif	/* bits/pthreadtypes.h */



#
# I don't know why it's needed...  I think we can drop it.
#
#diff -urN glibc-2.3.2-orig-debian/localedata/gen-locale.sh glibc-2.3.2/localedata/gen-locale.sh
#--- glibc-2.3.2-orig-debian/localedata/gen-locale.sh	2003-10-22 01:03:54.000000000 -0400
#+++ glibc-2.3.2/localedata/gen-locale.sh	2003-10-22 01:07:38.000000000 -0400
#@@ -47,6 +47,7 @@
# locale=`echo $locfile|sed 's|\([^.]*\)[.].*/LC_CTYPE|\1|'`
# charmap=`echo $locfile|sed 's|[^.]*[.]\(.*\)/LC_CTYPE|\1|'`
# 
#+echo "Running \"$0 $common_objpfx $localedef $locfile\""
# echo "Generating locale $locale.$charmap: this might take a while..."
# generate_locale `echo $charmap | sed -e s/SJIS/SHIFT_JIS/` $locale \
# 		$locale.$charmap


#
# the file is already removed.  (lock change)
#
#diff -urN glibc-2.3.2-orig-debian/malloc/thread-m.h glibc-2.3.2/malloc/thread-m.h
#--- glibc-2.3.2-orig-debian/malloc/thread-m.h	2003-10-22 01:06:10.000000000 -0400
#+++ glibc-2.3.2/malloc/thread-m.h	2003-10-22 01:07:38.000000000 -0400
#@@ -59,6 +59,28 @@
# #define mutex_unlock(m)		\
#   __libc_maybe_call2 (pthread_mutex_unlock, (m), (*(int *)(m) = 0))
# 
#+# if(defined __hppa__)
#+/* Since our lock structure does not tolerate being initialized to zero, we must
#+   modify the standard function calls made by malloc */
#+#  undef mutex_init
#+#  undef mutex_lock
#+#  undef mutex_trylock
#+#  undef mutex_unlock
#+#  define mutex_init(m)		\
#+	__libc_maybe_call (__pthread_mutex_init, (m, NULL), \
#+			(((m)->__m_lock.__spinlock = __LT_SPINLOCK_INIT),(*(int *)(m))) )
#+#  define mutex_lock(m)		\
#+	__libc_maybe_call (__pthread_mutex_lock, (m), \
#+			(__load_and_clear(&((m)->__m_lock.__spinlock)), 0))
#+#  define mutex_trylock(m)	\
#+	__libc_maybe_call (__pthread_mutex_trylock, (m), \
#+			(*(int *)(m) ? 1 : (__load_and_clear(&((m)->__m_lock.__spinlock)), 0)))
#+#  define mutex_unlock(m)	\
#+	__libc_maybe_call (__pthread_mutex_unlock, (m), \
#+			(((m)->__m_lock.__spinlock = __LT_SPINLOCK_INIT), (*(int *)(m))) )
#+# endif 
#+/* if(defined __hppa__) */
#+	
# #else
# 
# #define mutex_init(m)		\


#
# not in cvs.
#
#diff -urN glibc-2.3.2-orig-debian/sysdeps/hppa/atomicity.h glibc-2.3.2/sysdeps/hppa/atomicity.h
#--- glibc-2.3.2-orig-debian/sysdeps/hppa/atomicity.h	1969-12-31 19:00:00.000000000 -0500
#+++ glibc-2.3.2/sysdeps/hppa/atomicity.h	2003-10-22 01:07:38.000000000 -0400
#@@ -0,0 +1,55 @@
#+/* Low-level functions for atomic operations.  HP-PARISC version.
#+   Copyright (C) 1997,2001 Free Software Foundation, Inc.
#+   This file is part of the GNU C Library.
#+
#+   The GNU C Library is free software; you can redistribute it and/or
#+   modify it under the terms of the GNU Lesser General Public
#+   License as published by the Free Software Foundation; either
#+   version 2.1 of the License, or (at your option) any later version.
#+
#+   The GNU C Library is distributed in the hope that it will be useful,
#+   but WITHOUT ANY WARRANTY; without even the implied warranty of
#+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
#+   Lesser General Public License for more details.
#+
#+   You should have received a copy of the GNU Lesser General Public
#+   License along with the GNU C Library; if not, write to the Free
#+   Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA
#+   02111-1307 USA.  */
#+
#+#ifndef _ATOMICITY_H
#+#define _ATOMICITY_H	1
#+
#+#include <inttypes.h>
#+
#+#warning stub atomicity functions are not atomic
#+#warning CAO This will get implemented soon
#+
#+static inline int
#+__attribute__ ((unused))
#+exchange_and_add (volatile uint32_t *mem, int val)
#+{
#+  int result = *mem;
#+  *mem += val;
#+  return result;
#+}
#+
#+static inline void
#+__attribute__ ((unused))
#+atomic_add (volatile uint32_t *mem, int val)
#+{
#+  *mem += val;
#+}
#+
#+static inline int
#+__attribute__ ((unused))
#+compare_and_swap (volatile long int *p, long int oldval, long int newval)
#+{
#+  if (*p != oldval)
#+    return 0;
#+
#+  *p = newval;
#+  return 1;
#+}
#+
#+#endif /* atomicity.h */


#
# this file is removed.  but it may not be needed.
#
#diff -urN glibc-2.3.2-orig-debian/sysdeps/hppa/dl-fptr.c glibc-2.3.2/sysdeps/hppa/dl-fptr.c
#--- glibc-2.3.2-orig-debian/sysdeps/hppa/dl-fptr.c	2003-10-22 01:03:47.000000000 -0400
#+++ glibc-2.3.2/sysdeps/hppa/dl-fptr.c	2003-10-22 01:07:38.000000000 -0400
#@@ -30,7 +30,7 @@
# # include <pt-machine.h>
# 
# /* Remember, we use 0 to mean that a lock is taken on PA-RISC. */
#-static int __hppa_fptr_lock = 1;
#+static __atomic_lock_t __hppa_fptr_lock = __LT_SPINLOCK_ALT_INIT;
# #endif
# 
# /* Because ld.so is now versioned, these functions can be in their own
#@@ -127,7 +127,7 @@
# #ifdef _LIBC_REENTRANT
#   /* Release the lock.  Again, remember, zero means the lock is taken!  */
#   if (mem == NULL)
#-    __hppa_fptr_lock = 1;
#+    __hppa_fptr_lock = __LT_SPINLOCK_INIT;
# #endif
# 
#   /* Set bit 30 to indicate to $$dyncall that this is a PLABEL. */
#@@ -180,7 +180,7 @@
# 
# #ifdef _LIBC_REENTRANT
#   /* Release the lock. */
#-  __hppa_fptr_lock = 1;
#+  __hppa_fptr_lock = __LT_SPINLOCK_INIT;
# #endif
# }
# 
#@@ -190,6 +190,8 @@
#   Elf32_Addr addr = (Elf32_Addr) address;
#   struct hppa_fptr *f;
# 
#+  address = (void *)((unsigned long)address &~ 3); /* Clear the bottom two bits.  See make_fptr. */
#+  
# #ifdef _LIBC_REENTRANT
#   /* Make sure we are alone.  */
#   while (testandset (&__hppa_fptr_lock));
#@@ -204,7 +206,7 @@
# 
# #ifdef _LIBC_REENTRANT
#   /* Release the lock.   */
#-  __hppa_fptr_lock = 1;
#+  __hppa_fptr_lock = __LT_SPINLOCK_INIT;
# #endif
# 
#   return addr;


#
# not in cvs - I don't know it's needed.
#
#diff -urN glibc-2.3.2-orig-debian/sysdeps/unix/Makefile glibc-2.3.2/sysdeps/unix/Makefile
#--- glibc-2.3.2-orig-debian/sysdeps/unix/Makefile	2003-10-22 01:06:12.000000000 -0400
#+++ glibc-2.3.2/sysdeps/unix/Makefile	2003-10-22 01:07:38.000000000 -0400
#@@ -295,6 +295,7 @@
# 			  $(..)sysdeps/unix/Makefile
# 	$(make-target-directory)
# 	(echo '#include <errno.h>'; \
#+	 echo 'extern long int _no_syscall(void);'; \
# 	 echo 'long int _no_syscall (void)'; \
# 	 echo '{ __set_errno (ENOSYS); return -1L; }'; \
# 	 for call in $(unix-stub-syscalls); do \



#
# It should be put in.
#
diff -urN glibc-2.3.2-orig-debian/sysdeps/unix/sysv/linux/hppa/kernel_stat.h glibc-2.3.2/sysdeps/unix/sysv/linux/hppa/kernel_stat.h
--- glibc-2.3.2-orig-debian/sysdeps/unix/sysv/linux/hppa/kernel_stat.h	2003-10-22 01:03:48.000000000 -0400
+++ glibc-2.3.2/sysdeps/unix/sysv/linux/hppa/kernel_stat.h	2003-10-22 01:07:38.000000000 -0400
@@ -1,30 +1,30 @@
-/* definition of "struct stat" from the kernel */
+/* Definition of 'struct stat' taken from kernel, please keep up to date */
 struct kernel_stat {
-	unsigned long	st_dev;		/* dev_t is 32 bits on parisc */
-	unsigned long	st_ino;		/* 32 bits */
+	unsigned int	st_dev;		/* dev_t is 32 bits on parisc */
+	unsigned int	st_ino;		/* 32 bits */
 	unsigned short	st_mode;	/* 16 bits */
 	unsigned short	st_nlink;	/* 16 bits */
 	unsigned short	st_reserved1;	/* old st_uid */
 	unsigned short	st_reserved2;	/* old st_gid */
-	unsigned long	st_rdev;
-	unsigned long   st_size;
+	unsigned int	st_rdev;
+	unsigned int	st_size;
 	struct timespec st_atim;
-	struct timespec st_mtim;
-	struct timespec st_ctim;
-	long		st_blksize;
-	long		st_blocks;
-	unsigned long	__unused1;	/* ACL stuff */
-	unsigned long	__unused2;	/* network */
-	unsigned long	__unused3;	/* network */
-	unsigned long	__unused4;	/* cnodes */
+	struct timespec	st_mtim;
+	struct timespec	st_ctim;
+	int		st_blksize;
+	int		st_blocks;
+	unsigned int	__unused1;	/* ACL stuff */
+	unsigned int	__unused2;	/* network */
+	unsigned int	__unused3;	/* network */
+	unsigned int	__unused4;	/* cnodes */
 	unsigned short	__unused5;	/* netsite */
 	short		st_fstype;
-	unsigned long	st_realdev;
+	unsigned int	st_realdev;
 	unsigned short	st_basemode;
 	unsigned short	st_spareshort;
-	unsigned long	st_uid;
-	unsigned long   st_gid;
-	unsigned long	st_spare4[3];
+	unsigned int	st_uid;
+	unsigned int	st_gid;
+	unsigned int	st_spare4[3];
 };
 
 #define _HAVE_STAT_NSEC



#
# It's OK to put.
#
diff -urN glibc-2.3.2-orig-debian/sysdeps/unix/sysv/linux/hppa/mmap.c glibc-2.3.2/sysdeps/unix/sysv/linux/hppa/mmap.c
--- glibc-2.3.2-orig-debian/sysdeps/unix/sysv/linux/hppa/mmap.c	2003-10-22 01:03:48.000000000 -0400
+++ glibc-2.3.2/sysdeps/unix/sysv/linux/hppa/mmap.c	2003-10-22 01:07:38.000000000 -0400
@@ -37,7 +37,7 @@
 	
 	__ptr_t ret;
 
-	ret = INLINE_SYSCALL(mmap, 6, addr, len, prot, flags, fd, offset);
+	ret = (__ptr_t)INLINE_SYSCALL(mmap, 6, addr, len, prot, flags, fd, offset);
 
 	/* check if it's really a negative number */
 	if(((unsigned long)ret & 0xfffff000) == 0xfffff000)



#
# I don't know it's needed or not
#
#diff -urN glibc-2.3.2-orig-debian/sysdeps/unix/sysv/linux/hppa/umount.c glibc-2.3.2/sysdeps/unix/sysv/linux/hppa/umount.c
#--- glibc-2.3.2-orig-debian/sysdeps/unix/sysv/linux/hppa/umount.c	2003-10-22 01:03:48.000000000 -0400
#+++ glibc-2.3.2/sysdeps/unix/sysv/linux/hppa/umount.c	2003-10-22 01:07:38.000000000 -0400
#@@ -21,6 +21,7 @@
#    does down here.  */
# 
# extern long int __umount2 (const char *name, int flags);
#+extern long int __umount (const char * name);
# 
# long int
# __umount (const char *name)
